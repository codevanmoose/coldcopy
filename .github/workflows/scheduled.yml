name: Scheduled Maintenance

on:
  schedule:
    # Run daily at 2 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch:

jobs:
  # Database maintenance
  database-maintenance:
    runs-on: ubuntu-latest
    environment: production
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Partition maintenance
        run: |
          PGPASSWORD=${{ secrets.SUPABASE_DB_PASSWORD }} psql \
            -h ${{ secrets.SUPABASE_DB_HOST }} \
            -U postgres \
            -d postgres \
            -c "SELECT maintain_email_event_partitions();"
      
      - name: Refresh materialized views
        run: |
          PGPASSWORD=${{ secrets.SUPABASE_DB_PASSWORD }} psql \
            -h ${{ secrets.SUPABASE_DB_HOST }} \
            -U postgres \
            -d postgres << EOF
            SELECT refresh_campaign_analytics();
            SELECT refresh_workspace_usage_analytics();
            SELECT refresh_lead_engagement_scores();
            SELECT refresh_email_deliverability_metrics();
          EOF
      
      - name: Analyze tables
        run: |
          PGPASSWORD=${{ secrets.SUPABASE_DB_PASSWORD }} psql \
            -h ${{ secrets.SUPABASE_DB_HOST }} \
            -U postgres \
            -d postgres \
            -c "SELECT analyze_all_tables();"
      
      - name: Capture index usage stats
        run: |
          PGPASSWORD=${{ secrets.SUPABASE_DB_PASSWORD }} psql \
            -h ${{ secrets.SUPABASE_DB_HOST }} \
            -U postgres \
            -d postgres \
            -c "SELECT capture_index_usage_stats();"

  # Cleanup old data
  data-cleanup:
    runs-on: ubuntu-latest
    environment: production
    
    steps:
      - uses: actions/checkout@v4
      
      - uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          cd apps/api
          pip install -r requirements.txt
      
      - name: Clean old sync queue items
        run: |
          cd apps/api
          python -c "
          import asyncio
          from services.partition_manager import get_partition_manager
          
          async def cleanup():
              manager = await get_partition_manager('${{ secrets.DATABASE_URL }}')
              result = await manager.cleanupQueue(olderThanDays=7)
              print(f'Cleaned up {result['deleted']} old queue items')
          
          asyncio.run(cleanup())
          "
      
      - name: Clean expired sessions
        run: |
          PGPASSWORD=${{ secrets.SUPABASE_DB_PASSWORD }} psql \
            -h ${{ secrets.SUPABASE_DB_HOST }} \
            -U postgres \
            -d postgres \
            -c "DELETE FROM auth.sessions WHERE expires_at < NOW();"
      
      - name: Archive old audit logs
        run: |
          # Archive audit logs older than 90 days
          PGPASSWORD=${{ secrets.SUPABASE_DB_PASSWORD }} psql \
            -h ${{ secrets.SUPABASE_DB_HOST }} \
            -U postgres \
            -d postgres << EOF
            INSERT INTO audit_logs_archive 
            SELECT * FROM audit_logs 
            WHERE created_at < NOW() - INTERVAL '90 days';
            
            DELETE FROM audit_logs 
            WHERE created_at < NOW() - INTERVAL '90 days';
          EOF

  # Dependency updates
  dependency-updates:
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Check for npm updates
        uses: actions/github-script@v7
        with:
          script: |
            const { execSync } = require('child_process');
            
            try {
              const outdated = execSync('cd apps/web && npm outdated --json', { encoding: 'utf-8' });
              const packages = JSON.parse(outdated);
              
              if (Object.keys(packages).length > 0) {
                const issue = await github.rest.issues.create({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  title: 'Weekly dependency updates available',
                  body: `The following packages have updates available:\n\n${
                    Object.entries(packages).map(([name, info]) => 
                      `- **${name}**: ${info.current} â†’ ${info.latest}`
                    ).join('\n')
                  }`,
                  labels: ['dependencies', 'maintenance']
                });
              }
            } catch (e) {
              console.log('No outdated packages found');
            }

  # Security scanning
  security-scan:
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: 'fs'
          scan-ref: '.'
          format: 'table'
          severity: 'CRITICAL,HIGH,MEDIUM'
          exit-code: '0'
      
      - name: Run npm audit
        run: |
          cd apps/web
          npm audit --production || true
      
      - name: Run pip audit
        run: |
          cd apps/api
          pip install pip-audit
          pip-audit || true
      
      - name: Create security report
        if: failure()
        uses: actions/github-script@v7
        with:
          script: |
            github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: 'Security vulnerabilities detected',
              body: 'Automated security scan found vulnerabilities. Check the workflow logs for details.',
              labels: ['security', 'urgent']
            });

  # Backup verification
  backup-verification:
    runs-on: ubuntu-latest
    environment: production
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Verify latest backup
        run: |
          # Check if backup was created in last 24 hours
          aws s3 ls s3://${{ secrets.BACKUP_BUCKET }}/backups/ \
            --recursive \
            --human-readable \
            --summarize \
            | grep "$(date -u +%Y-%m-%d)" || exit 1
      
      - name: Test backup integrity
        run: |
          # Download and verify latest backup
          LATEST_BACKUP=$(aws s3 ls s3://${{ secrets.BACKUP_BUCKET }}/backups/ \
            | sort | tail -n 1 | awk '{print $4}')
          
          aws s3 cp s3://${{ secrets.BACKUP_BUCKET }}/backups/$LATEST_BACKUP /tmp/
          
          # Verify backup integrity
          gpg --verify /tmp/$LATEST_BACKUP.sig /tmp/$LATEST_BACKUP
          
          # Test restore (dry run)
          pg_restore --list /tmp/$LATEST_BACKUP > /dev/null

  # Performance monitoring
  performance-check:
    runs-on: ubuntu-latest
    environment: production
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Check slow queries
        run: |
          SLOW_QUERIES=$(PGPASSWORD=${{ secrets.SUPABASE_DB_PASSWORD }} psql \
            -h ${{ secrets.SUPABASE_DB_HOST }} \
            -U postgres \
            -d postgres \
            -t -c "SELECT COUNT(*) FROM pg_stat_statements WHERE mean_exec_time > 1000")
          
          if [ $SLOW_QUERIES -gt 10 ]; then
            echo "Warning: $SLOW_QUERIES slow queries detected"
            # Create alert
          fi
      
      - name: Check cache hit rates
        run: |
          # Check Redis cache hit rate
          CACHE_STATS=$(redis-cli -h ${{ secrets.REDIS_HOST }} \
            -a ${{ secrets.REDIS_PASSWORD }} \
            INFO stats | grep -E "keyspace_hits|keyspace_misses")
          
          # Calculate hit rate and alert if below threshold
          # Implementation depends on your monitoring setup
      
      - name: Check API response times
        run: |
          # Run API performance tests
          npm install -g autocannon
          
          autocannon \
            -c 10 \
            -d 30 \
            -H "Authorization: Bearer ${{ secrets.API_TEST_TOKEN }}" \
            ${{ secrets.API_URL }}/health
          
          # Check if response times are within acceptable range

  # Generate weekly report
  weekly-report:
    if: github.event.schedule == '0 2 * * 0' # Only on Sundays
    runs-on: ubuntu-latest
    environment: production
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Generate metrics report
        run: |
          # Collect various metrics
          # Database size, active users, email volume, etc.
          # Generate markdown report
      
      - name: Send report
        uses: dawidd6/action-send-mail@v3
        with:
          server_address: smtp.gmail.com
          server_port: 465
          username: ${{ secrets.EMAIL_USERNAME }}
          password: ${{ secrets.EMAIL_PASSWORD }}
          subject: ColdCopy Weekly Maintenance Report
          to: ops@coldcopy.ai
          from: GitHub Actions
          body: file://./weekly-report.md